{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e46c506-3bc9-41ed-8651-d45045b89099",
   "metadata": {},
   "source": [
    "## This is a bigram langauge model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e9a6f53e-e546-4d67-b456-2ea75b1a63c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import  functional as F\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device\n",
    "\n",
    "block_size = 8\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8ed85294-33f5-42a5-a705-e0607341e15e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  DOROTHY AND THE WIZARD IN OZ\n",
      "\n",
      "  BY\n",
      "\n",
      "  L. FRANK BAUM\n",
      "\n",
      "  AUTHOR OF THE WIZARD OF OZ, THE LAND OF OZ, OZMA OF OZ, ETC.\n",
      "\n",
      "  ILLUSTRATED BY JOHN R. NEILL\n",
      "\n",
      "  BOOKS OF WONDER WILLIAM MORROW & CO., INC. NEW \n"
     ]
    }
   ],
   "source": [
    "with open('wizard_of_oz.txt','r',encoding='utf-8') as f:\n",
    "    text= f.read()\n",
    "\n",
    "print(text[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2746004d-71f9-4574-be09-4ffd154595ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '\"', '&', \"'\", '(', ')', '*', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "# puttig it into a vocabulary list\n",
    "chars = sorted(set(text))\n",
    "print(chars)\n",
    "covab_size = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4e4a4b2e-6f52-4761-ba2e-e31c3bd65f29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  1, 28, 39, 42, 39, 44, 32, 49,  1, 25, 38, 28,  1, 44, 32, 29,  1,\n",
       "        47, 33, 50, 25, 42, 28,  1, 33, 38,  1, 39, 50,  0,  0,  1,  1, 26, 49,\n",
       "         0,  0,  1,  1, 36, 11,  1, 30, 42, 25, 38, 35,  1, 26, 25, 45, 37,  0,\n",
       "         0,  1,  1, 25, 45, 44, 32, 39, 42,  1, 39, 30,  1, 44, 32, 29,  1, 47,\n",
       "        33, 50, 25, 42, 28,  1, 39, 30,  1, 39, 50,  9,  1, 44, 32, 29,  1, 36,\n",
       "        25, 38, 28,  1, 39, 30,  1, 39, 50,  9])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using a tocanizer\n",
    "string_to_int = {ch:i for i,ch in enumerate(chars)}\n",
    "int_to_string = {i:ch for i,ch in enumerate(chars)}\n",
    "encode = lambda s: [string_to_int[c] for c in s]\n",
    "decode = lambda l: ''.join([int_to_string[i] for i in l])\n",
    "\n",
    "\n",
    "data = torch.tensor(encode(text),dtype=torch.long)\n",
    "data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a8f7280c-ce46-4f20-889c-3139975ab654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "# convert string to integers\n",
    "encoded_hello = encode('hello')\n",
    "decoded_hello = decode(encoded_hello)\n",
    "print(decoded_hello)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664cc723-4a6f-46cc-83e4-d84ea85aa7ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7a52ebf0-d850-4957-870a-33e86441b672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([119697,  43193, 150726,  63937])\n",
      "inputs:\n",
      "tensor([[57,  1, 72, 73, 71, 68, 67, 60],\n",
      "        [58, 54, 73, 61, 24,  3,  1, 61],\n",
      "        [66, 58, 11,  3,  0,  0,  3, 33],\n",
      "        [68, 76, 72, 62, 67, 60,  1, 67]], device='cuda:0')\n",
      "targets\n",
      "tensor([[ 1, 72, 73, 71, 68, 67, 60],\n",
      "        [54, 73, 61, 24,  3,  1, 61],\n",
      "        [58, 11,  3,  0,  0,  3, 33],\n",
      "        [76, 72, 62, 67, 60,  1, 67]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "n = int(0.8 * len(data))\n",
    "\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "len(train_data),len(val_data)\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size,(batch_size,)) # this creates a random integer\n",
    "    print(ix)\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size] for i in ix])\n",
    "    x,y = x.to(device),y.to(device)\n",
    "    return x,y\n",
    "\n",
    "\n",
    "x,y = get_batch('train')\n",
    "print('inputs:')\n",
    "print(x)\n",
    "print('targets')\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe1c40a-718d-456a-ba79-59c9487a8d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self,vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embeddings_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self,index,targets):\n",
    "        logits = self.token_embeddings_table(index)\n",
    "        return logits\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e0acadf4-212d-456b-90ce-8306171c6fee",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m a\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m x,y,z \u001b[38;5;241m=\u001b[39m a\n\u001b[0;32m      3\u001b[0m a \u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39mview(x,y,z)\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "a= torch.rand(2,3,4)\n",
    "x,y,z = a.shape\n",
    "a = a.view(x,y,z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0549801a-2c68-4260-8c5c-b3f9902868e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0155, 0.1835, 0.4760, 0.0298],\n",
       "         [0.6542, 0.8952, 0.3831, 0.9015],\n",
       "         [0.8611, 0.7285, 0.7285, 0.9845]],\n",
       "\n",
       "        [[0.4871, 0.6178, 0.3161, 0.6479],\n",
       "         [0.7433, 0.8401, 0.3380, 0.9130],\n",
       "         [0.4296, 0.6573, 0.3900, 0.0149]]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d466d5-4e3c-46b7-845e-59730d7d811a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f16753-35b6-46e7-a31f-db4d410acc10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ac507f-cfa8-40e8-bfce-94ccd8868d6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d523c74d-aa69-4f45-bf83-8f1217df16b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([1]) target is tensor(1)\n",
      "when input is tensor([1, 1]) target is tensor(28)\n",
      "when input is tensor([ 1,  1, 28]) target is tensor(39)\n",
      "when input is tensor([ 1,  1, 28, 39]) target is tensor(42)\n",
      "when input is tensor([ 1,  1, 28, 39, 42]) target is tensor(39)\n",
      "when input is tensor([ 1,  1, 28, 39, 42, 39]) target is tensor(44)\n",
      "when input is tensor([ 1,  1, 28, 39, 42, 39, 44]) target is tensor(32)\n",
      "when input is tensor([ 1,  1, 28, 39, 42, 39, 44, 32]) target is tensor(49)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x= train_data[: block_size]\n",
    "y= train_data[1:block_size+1]\n",
    "\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print('when input is',context,'target is',target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b1b119ff-3d95-4a47-b468-1d2e22b7152e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0],\n",
       "        [0, 0, 0]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint(1,(2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "339bf5e2-8aa4-47ea-8e5d-a24a7a665d06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([247, 101, 333, 222, 134])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix = torch.randint(500 - 100,(5,))\n",
    "ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea793093-a5e6-4308-a1ee-466e9e250d16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda-gpt",
   "language": "python",
   "name": "cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
